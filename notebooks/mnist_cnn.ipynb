{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Introduction to Deep Learning with Keras and TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you understand the fundamentals of deep learning, this demo will walk through the basic steps of building a toy model for classifying handwritten numbers with accuracies surpassing 95%. This model will be a convolutional neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "04QgGZc9bF5D"
   },
   "source": [
    "## The Task for the AI\n",
    "\n",
    "Our goal is to construct and train an artificial neural network on thousands of images of handwritten digits so that it may successfully identify others when presented. The data that will be incorporated is the MNIST database which contains 60,000 images for training and 10,000 test images. We will use the Keras Python API with TensorFlow as the backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnrWf3PCEzXL"
   },
   "source": [
    "![MNIST](https://www.researchgate.net/profile/Kofi_Appiah/publication/252028600/figure/fig2/AS:298067136925718@1448076151592/Some-samples-of-the-MNIST-database.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "source": [
    "## Prerequisite Python Modules\n",
    "\n",
    "First, some software needs to be loaded into the Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "7NAbSZiaoJ4z"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    if tf.__version__.startswith('2.4'):\n",
    "        pass\n",
    "    else:\n",
    "        !pip3 install tensorflow-gpu==2.4.0\n",
    "except:\n",
    "    !pip3 install tensorflow-gpu==2.4.0\n",
    "    \n",
    "import tensorflow as tf\n",
    "import numpy as np                   # advanced math library\n",
    "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
    "import random                        # for generating random numbers\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from tensorflow.keras.datasets import mnist     # MNIST dataset is included in Keras\n",
    "from tensorflow.keras.models import Sequential  # Model type to be used\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, \\\n",
    "    ZeroPadding2D, GlobalAveragePooling2D, Flatten, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing Convolution! What is it?\n",
    "Before, we built a network that accepts the normalized pixel values of each value and operates soley on those values. What if we could instead feed different features (e.g. **curvature, edges**) of each image into a network, and have the network learn which features are important for classifying an image?\n",
    "\n",
    "This possible through convolution! Convolution applies **kernels** (filters) that traverse through each image and generate **feature maps**.\n",
    "![conf](https://miro.medium.com/max/500/1*GcI7G-JLAQiEoCON7xFbhg.gif)\n",
    "In the above example, the image is a 5 x 5 matrix and the kernel going over it is a 3 x 3 matrix. A dot product operation takes place between the image and the kernel and the convolved feature is generated. Each kernel in a CNN learns a different characteristic of an image.\n",
    "\n",
    "Kernels are often used in photoediting software to apply blurring, edge detection, sharpening, etc.\n",
    "![filters](https://miro.medium.com/max/684/1*wFVu-TnKupy86DgZwvMcdw.png)\n",
    "Kernels in deep learning networks are used in similar ways, i.e. highlighting some feature. Combined with a system called max pooling, the non-highlighted elements are discarded from each feature map, leaving only the features of interest, reducing the number of learned parameters, and decreasing the computational cost (e.g. system memory).\n",
    "![max_pool](data:image/png;base64,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)\n",
    "We can also take convolutions of convolutions -- we can stack as many convolutions as we want, as long as there are enough pixels to fit a kernel.\n",
    "\n",
    "*Warning: What you may find down there in those deep convolutions may not appear recognizable to you.*\n",
    "![meme](https://miro.medium.com/max/5668/1*pPPFfrlPQsXeG3eZA0-v2A.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FP5258xjs-v"
   },
   "source": [
    "\n",
    "## Loading Training Data\n",
    "\n",
    "The MNIST dataset is conveniently bundled within Keras, and we can easily analyze some of its features in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "BPZ68wASog_I"
   },
   "outputs": [],
   "source": [
    "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatting the input data layer\n",
    "\n",
    "Now we do want to use a `28` by `28` image! But we need to add an extra dimension, representing the channel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, do some formatting\n",
    "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
    "\n",
    "# add an additional dimension to represent the single-channel\n",
    "\n",
    "# change integers to 32-bit floating point numbers\n",
    "\n",
    "# normalize each value for each pixel for the entire vector for each input\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then modify our classes (unique digits) to be in the one-hot format, i.e.\n",
    "\n",
    "```\n",
    "0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "2 -> [0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
    "etc.\n",
    "```\n",
    "\n",
    "If the final output of our network is very close to one of these classes, then it is most likely that class. For example, if the final output is:\n",
    "\n",
    "```\n",
    "[0, 0.94, 0, 0, 0, 0, 0.06, 0, 0]\n",
    "```\n",
    "then it is most probable that the image is that of the digit `1`.\n",
    "\n",
    "Format `Y_train` and `Y_test` to a one hot encoding. Try using the `tensorflow.keras.utils.to_categorical` method for this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format to one-hot encoding here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "Build a model with 4 convolutional layers, and two Dense layers. Use the following specifications:\n",
    "* All convolutional layers should have a filter size of `(3, 3)`\n",
    "* Use batch normalization after each convolutional layer\n",
    "* Use ReLU activation functions\n",
    "* Use a MaxPool operation on the 2nd, 3rd adn 4th convolution layer, after the ReLU\n",
    "* Afther the 4th convolutional layer, flatten the output using `Flatten()`\n",
    "* Add two Dense layers with 512 and 10 outputs, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# Convolution Layer 1\n",
    "# 32 different 3x3 kernels -- so 32 feature maps\n",
    "# normalize each feature map before activation\n",
    "# activation\n",
    "\n",
    "\n",
    "# Convolution Layer 2\n",
    "# 32 different 3x3 kernels -- so 32 feature maps\n",
    "# normalize each feature map before activation\n",
    "# activation\n",
    "# Pool the max values over a 2x2 kernel\n",
    "\n",
    "\n",
    "# Convolution Layer 3\n",
    "# 64 different 3x3 kernels -- so 64 feature maps\n",
    "# normalize each feature map before activation\n",
    "# activation\n",
    "\n",
    "\n",
    "# Convolution Layer 4\n",
    "# 64 different 3x3 kernels -- so 64 feature maps\n",
    "# normalize each feature map before activation\n",
    "# activation\n",
    "# Pool the max values over a 2x2 kernel\n",
    "# Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "# 512 FCN nodes\n",
    "# normalization\n",
    "# activation\n",
    "\n",
    "# Fully Connected Layer 6                       \n",
    "# 20% dropout of randomly selected nodes\n",
    "# final 10 FCN nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the built model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use the same optimizer. Call model.compile here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!\n",
    "This is the fun part! \n",
    "\n",
    "The batch size determines over how much data per step is used to compute the loss function, gradients, and back propagation. Large batch sizes allow the network to complete it's training faster; however, there are other factors beyond training speed to consider.\n",
    "\n",
    "Too large of a batch size smoothes the local minima of the loss function, causing the optimizer to settle in one because it thinks it found the global minimum.\n",
    "\n",
    "Too small of a batch size creates a very noisy loss function, and the optimizer may never find the global minimum.\n",
    "\n",
    "So a good batch size may take some trial and error to find!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model.fit() function here. We recommend setting verbose=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two numbers, in order, represent the value of the loss function of the network on the training set, and the overall accuracy of the network on the training data. But how does it do on data it did not train on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model's Accuracy on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call model.evaluate()\n",
    "\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the output\n",
    "\n",
    "It's always a good idea to inspect the output and make sure everything looks sane. Here we'll look at some examples it gets right, and some examples it gets wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# choose any image to want by specifying the index\n",
    "img = X_test[3]\n",
    "img = np.expand_dims(img, axis=0) # Keras requires the image to be in 4D, so we add an extra dimension to it.\n",
    "\n",
    "# Not important to understand how this function work -- It just plots a convolution layer\n",
    "\n",
    "def visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "        \n",
    "    _convout1_f = Model(model.inputs, layer.output)\n",
    "    \n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([X])\n",
    "\n",
    "    convolutions = convout1_f(img)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "    \n",
    "    m = convolutions.shape[-1]\n",
    "    n = int(np.ceil(np.sqrt(m)))\n",
    "        \n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(15,12))\n",
    "    for i in range(m):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[:,:,i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(convLayer01) # visualize first set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(convLayer02) # visualize second set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(convLayer03)# visualize third set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(convLayer04)# visualize fourth set of feature maps"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rX8mhOLljYeM"
   ],
   "name": "beginner.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
